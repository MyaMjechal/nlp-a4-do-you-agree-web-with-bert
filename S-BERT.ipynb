{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9NSvsTr4eFA"
      },
      "source": [
        "# [Sentence-BERT](https://arxiv.org/pdf/1908.10084.pdf)\n",
        "\n",
        "[Reference Code](https://www.pinecone.io/learn/series/nlp/train-sentence-transformers-softmax/)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "3DdqdElC5YSl",
        "outputId": "9b98f6b0-5a39-4b21-a646-c7327c126aec"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-3.3.2-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.10.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.12)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.28.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.3.2-py3-none-any.whl (485 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m485.4/485.4 kB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, dill, multiprocess, datasets\n",
            "Successfully installed datasets-3.3.2 dill-0.3.8 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "xGa4trgr4eFE",
        "outputId": "0b79ac36-449d-43a4-cfec-ad966037fe00"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cpu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "import os\n",
        "import math\n",
        "import re\n",
        "from   random import *\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Set GPU device\n",
        "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "\n",
        "# os.environ['http_proxy']  = 'http://192.41.170.23:3128'\n",
        "# os.environ['https_proxy'] = 'http://192.41.170.23:3128'\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device = 'cpu'\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SML5CKdh4eFH"
      },
      "source": [
        "## 1. Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHGwLR8w4eFI"
      },
      "source": [
        "### Train, Test, Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vdpaE68F4eFI",
        "outputId": "54306f57-e5d3-4ddc-81a5-aca9d304aab2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'premise': Value(dtype='string', id=None),\n",
              " 'hypothesis': Value(dtype='string', id=None),\n",
              " 'label': ClassLabel(names=['entailment', 'neutral', 'contradiction'], id=None),\n",
              " 'idx': Value(dtype='int32', id=None)}"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "import datasets\n",
        "\n",
        "mnli = datasets.load_dataset('glue', 'mnli')\n",
        "mnli['train'].features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ep_EGfgM4eFJ",
        "outputId": "efad239c-ff25-4db0-bf2c-00f6a8e58d4e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['train', 'validation_matched', 'validation_mismatched', 'test_matched', 'test_mismatched'])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "# List of datasets to remove 'idx' column from\n",
        "mnli.column_names.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "6RtWhSVu4eFK"
      },
      "outputs": [],
      "source": [
        "# Remove 'idx' column from each dataset\n",
        "for column_names in mnli.column_names.keys():\n",
        "    mnli[column_names] = mnli[column_names].remove_columns('idx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_B3QIw7M4eFK",
        "outputId": "eced6b60-8087-4652-ec4b-4fe152d6cc86"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['train', 'validation_matched', 'validation_mismatched', 'test_matched', 'test_mismatched'])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "mnli.column_names.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gledN8Oo4eFL",
        "outputId": "689b3459-f3e6-4541-9c86-5857ea2e3891"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "np.unique(mnli['train']['label'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the number of rows in each split of MNLI\n",
        "print(f\"Train set size: {mnli['train'].num_rows}\")\n",
        "print(f\"Matched validation set size: {mnli['validation_matched'].num_rows}\")\n",
        "print(f\"Mismatched validation set size: {mnli['validation_mismatched'].num_rows}\")\n",
        "print(f\"Matched test set size: {mnli['test_matched'].num_rows}\")\n",
        "print(f\"Mismatched test set size: {mnli['test_mismatched'].num_rows}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BO_iyljN6Rqx",
        "outputId": "86e16083-d1fb-4251-d1d1-97c3966835be"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set size: 392702\n",
            "Matched validation set size: 9815\n",
            "Mismatched validation set size: 9832\n",
            "Matched test set size: 9796\n",
            "Mismatched test set size: 9847\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import DatasetDict\n",
        "\n",
        "# Use only MNLI dataset\n",
        "raw_dataset = DatasetDict({\n",
        "    'train': mnli['train'].shuffle(seed=55).select(list(range(1000))),\n",
        "    'test': mnli['test_mismatched'].shuffle(seed=55).select(list(range(1000))),\n",
        "    'validation': mnli['validation_mismatched'].shuffle(seed=55).select(list(range(1000)))\n",
        "})\n",
        "#remove .select(list(range(1000))) in order to use full dataset\n",
        "raw_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_jJEWUE64HH",
        "outputId": "97c372ba-abee-4a82-8be9-029948054724"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['premise', 'hypothesis', 'label'],\n",
              "        num_rows: 1000\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['premise', 'hypothesis', 'label'],\n",
              "        num_rows: 1000\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['premise', 'hypothesis', 'label'],\n",
              "        num_rows: 1000\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Va8no31V4eFN"
      },
      "source": [
        "## 2. Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "KRt8P6KS4eFN"
      },
      "outputs": [],
      "source": [
        "# from transformers import BertTokenizer\n",
        "\n",
        "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch\n",
        "\n",
        "# class CustomBERTTokenizer:\n",
        "#     def __init__(self, word2id, max_len=1000):\n",
        "#         self.word2id = word2id\n",
        "#         self.id2word = {v: k for k, v in self.word2id.items()}\n",
        "#         self.vocab_size = len(self.word2id)\n",
        "#         self.max_len = max_len\n",
        "#         self.pad_token_id = self.word2id.get(\"[PAD]\", 0)\n",
        "#         self.unk_token_id = self.word2id.get(\"[UNK]\", 1)\n",
        "#         self.cls_token_id = self.word2id.get(\"[CLS]\", 2)\n",
        "#         self.sep_token_id = self.word2id.get(\"[SEP]\", 3)\n",
        "\n",
        "#     def __call__(self, sentences, padding=\"max_length\", max_length=None, truncation=True):\n",
        "#         \"\"\"Tokenizes sentences with consistent padding and truncation.\"\"\"\n",
        "#         if isinstance(sentences, str):\n",
        "#             sentences = [sentences]\n",
        "\n",
        "#         input_ids = []\n",
        "#         attention_masks = []\n",
        "\n",
        "#         for sentence in sentences:\n",
        "#             # Tokenize and convert words to IDs\n",
        "#             token_ids = [self.word2id.get(word, self.unk_token_id) for word in sentence.split()]\n",
        "\n",
        "#             # Set `max_length` if not provided\n",
        "#             if max_length is None:\n",
        "#                 max_length = self.max_len\n",
        "\n",
        "#             # Apply truncation **before** adding special tokens\n",
        "#             token_ids = token_ids[: max_length - 2]  # Reserve space for [CLS] & [SEP]\n",
        "\n",
        "#             # Add special tokens\n",
        "#             token_ids = [self.cls_token_id] + token_ids + [self.sep_token_id]\n",
        "\n",
        "#             # Create attention mask\n",
        "#             attention_mask = [1] * len(token_ids)\n",
        "\n",
        "#             # **Ensure sequences are always padded to `max_length`**\n",
        "#             if padding == \"max_length\":\n",
        "#                 padding_length = max_length - len(token_ids)\n",
        "#                 token_ids.extend([self.pad_token_id] * padding_length)\n",
        "#                 attention_mask.extend([0] * padding_length)\n",
        "\n",
        "#             input_ids.append(torch.tensor(token_ids, dtype=torch.long))\n",
        "#             attention_masks.append(torch.tensor(attention_mask, dtype=torch.long))\n",
        "\n",
        "#         return {\n",
        "#             \"input_ids\": torch.stack(input_ids),\n",
        "#             \"attention_mask\": torch.stack(attention_masks)\n",
        "#         }\n",
        "\n",
        "#     def decode(self, token_ids):\n",
        "#         \"\"\"Converts token IDs back into readable text.\"\"\"\n",
        "#         if isinstance(token_ids, torch.Tensor):\n",
        "#             token_ids = token_ids.tolist()\n",
        "\n",
        "#         return \" \".join([self.id2word.get(idx, \"[UNK]\") for idx in token_ids if idx not in {self.pad_token_id, self.cls_token_id, self.sep_token_id}])"
      ],
      "metadata": {
        "id": "p6trF87sJNST"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomBERTTokenizer:\n",
        "  def __init__(self, word2id):\n",
        "      self.word2id = word2id\n",
        "      self.id2word = {v: k for k, v in self.word2id.items()}\n",
        "      self.vocab_size = len(self.word2id)\n",
        "      self.max_len = max_len\n",
        "\n",
        "  def encode(self, sentences):\n",
        "      output = {}\n",
        "      output['input_ids'] = []\n",
        "      output['attention_mask'] = []\n",
        "      for sentence in sentences:\n",
        "        # TODO don't forget to change UNK back\n",
        "          input_ids = [self.word2id.get(word, self.word2id['[PAD]']) for word in sentence.split()]\n",
        "          n_pad = self.max_len - len(input_ids)\n",
        "          input_ids.extend([0] * n_pad)\n",
        "          att_mask = [1 if idx != 0 else 0 for idx in input_ids]  # Create attention mask\n",
        "          output['input_ids'].append(torch.tensor(input_ids))  # Convert to tensor\n",
        "          output['attention_mask'].append(torch.tensor(att_mask))  # Convert to tensor\n",
        "      return output\n",
        "\n",
        "  def decode(self, ids):\n",
        "      return ' '.join([self.id2word.get(idx.item(), '[PAD]') for idx in ids])"
      ],
      "metadata": {
        "id": "USSQRBxDg-Ak"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class CustomBERTTokenizer:\n",
        "#     def __init__(self, word2id):\n",
        "#         self.word2id = word2id\n",
        "#         self.id2word = {v: k for k, v in self.word2id.items()}\n",
        "#         self.vocab_size = len(self.word2id)\n",
        "#         self.max_len = max_len\n",
        "\n",
        "#     def encode(self, sentences):\n",
        "#         output = {}\n",
        "#         output['input_ids'] = []\n",
        "#         output['attention_mask'] = []\n",
        "#         for sentence in sentences:\n",
        "#             input_ids = [self.word2id.get(word, self.word2id['[UNK]']) for word in sentence.split()]\n",
        "#             n_pad = self.max_len - len(input_ids)\n",
        "#             input_ids.extend([0] * n_pad)\n",
        "#             att_mask = [1 if idx != 0 else 0 for idx in input_ids]  # Create attention mask\n",
        "#             output['input_ids'].append(torch.tensor(input_ids))  # Convert to tensor\n",
        "#             output['attention_mask'].append(torch.tensor(att_mask))  # Convert to tensor\n",
        "#         return output\n",
        "\n",
        "#     def decode(self, ids):\n",
        "#         return ' '.join([self.id2word.get(idx.item(), '[UNK]') for idx in ids])"
      ],
      "metadata": {
        "id": "q3c0Kl6cW8aU"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "bert_args = pickle.load(open('models/bert_args.pkl', 'rb'))\n",
        "vocab_size = bert_args['vocab_size']\n",
        "word2id = bert_args['word2id']\n",
        "batch_size = bert_args['batch_size']\n",
        "max_mask = bert_args['max_mask']\n",
        "max_len = bert_args['max_len']\n",
        "n_layers = bert_args['n_layers']\n",
        "n_heads = bert_args['n_heads']\n",
        "d_model = bert_args['d_model']\n",
        "d_ff = bert_args['d_ff']\n",
        "d_k = bert_args['d_k']\n",
        "d_v = bert_args['d_v']\n",
        "n_segments = bert_args['n_segments']"
      ],
      "metadata": {
        "id": "ywb-1rLTGSca"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Add '[UNK]' to word2id if it does not exist\n",
        "# # TODO revise BERT GPU model to add UNK in special tokens\n",
        "# if \"[UNK]\" not in word2id:\n",
        "#     word2id[\"[UNK]\"] = len(word2id)  # Assign the next available index"
      ],
      "metadata": {
        "id": "XiKGbGCgjB_x"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = CustomBERTTokenizer(word2id)"
      ],
      "metadata": {
        "id": "ehRt91fzL3GW"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "7e81c0c326e04a18803754d5e904e5fb",
            "ebcae985a50346f69f7ddb692afe8189",
            "c624ed196d7441bc9a410c405f7acc7f",
            "d5d0729cf41f4d31b477dff131126b9e",
            "77405024f8064cd4a170025915c8471b",
            "75d9594f9de24dbdb0a418bf80c8aad2",
            "768216801daa4cfd83501973a88ceb02",
            "688dd0efc83246af86c090ecf240f4c0",
            "d39473546d884aff859874ff5f490912",
            "e922d291ba2f42be96083ef95c6c73ad",
            "ac12b1cc0ab747d59ed84e8a96c598cd",
            "5a3b3c296f184bd99d4e7250804c793a",
            "4a9c26e8416b4d85b9c59665fe2b4a8d",
            "067e14930efb4276a6760e062851b097",
            "4e1e0d8e6ae443ee9237ad0f5cc9e160",
            "8dc9dd0af210478292f55d5313215c5a",
            "d6caa264a4b842fc91e91f60c7e62db6",
            "b2b960b3d485497d9bcc3fbc3516e204",
            "028633e30f494158a0434d9967575635",
            "c7ae49b0f716435087acb1100fefe424",
            "78fa846e08054c8abad5ba11eee47c3b",
            "9bedd0fcab51468780fae38a7b8e5225",
            "5c36d2e081054584a8fd7ec498847191",
            "9c8649c87f8d44e39b08f423d31aebb3",
            "0eddb1d78814464e85040352e02b3944",
            "d33e2358fe0a4d6a9ca06b5d3e89e8b1",
            "f9d3fd2a50d2443f83862752de47f421",
            "ccff32da445c4ea78ded721be7ba6b90",
            "dbdcc8c18e1549aaba47941c37b81b86",
            "5c0ce57ad8d345a5b090aeec1484ebca",
            "76c85b7735774ae3bc0a9a880498155f",
            "5b1376d55c474745bb8812c67a992d50",
            "608ac528701d4cb9947a32447a4fd7e6"
          ]
        },
        "id": "ZAVQaxVv4eFO",
        "outputId": "ddb5b359-c156-49c0-a17e-83b7173ab8a7"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7e81c0c326e04a18803754d5e904e5fb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5a3b3c296f184bd99d4e7250804c793a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5c36d2e081054584a8fd7ec498847191"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "def preprocess_function(examples):\n",
        "    # Tokenize the premise\n",
        "    premise_result = tokenizer.encode(\n",
        "        examples['premise'])\n",
        "    #num_rows, max_seq_length\n",
        "    # Tokenize the hypothesis\n",
        "    hypothesis_result = tokenizer.encode(\n",
        "        examples['hypothesis'])\n",
        "    #num_rows, max_seq_length\n",
        "    # Extract labels\n",
        "    labels = examples[\"label\"]\n",
        "    #num_rows\n",
        "    return {\n",
        "        \"premise_input_ids\": premise_result[\"input_ids\"],\n",
        "        \"premise_attention_mask\": premise_result[\"attention_mask\"],\n",
        "        \"hypothesis_input_ids\": hypothesis_result[\"input_ids\"],\n",
        "        \"hypothesis_attention_mask\": hypothesis_result[\"attention_mask\"],\n",
        "        \"labels\" : labels\n",
        "    }\n",
        "\n",
        "tokenized_datasets = raw_dataset.map(\n",
        "    preprocess_function,\n",
        "    batched=True,\n",
        ")\n",
        "\n",
        "tokenized_datasets = tokenized_datasets.remove_columns(['premise','hypothesis','label'])\n",
        "tokenized_datasets.set_format(\"torch\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4LntxVT4eFP",
        "outputId": "842aa480-73f5-45ef-93e5-e381af96f962"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['premise_input_ids', 'premise_attention_mask', 'hypothesis_input_ids', 'hypothesis_attention_mask', 'labels'],\n",
              "        num_rows: 1000\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['premise_input_ids', 'premise_attention_mask', 'hypothesis_input_ids', 'hypothesis_attention_mask', 'labels'],\n",
              "        num_rows: 1000\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['premise_input_ids', 'premise_attention_mask', 'hypothesis_input_ids', 'hypothesis_attention_mask', 'labels'],\n",
              "        num_rows: 1000\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ],
      "source": [
        "tokenized_datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKdvRpW-4eFQ"
      },
      "source": [
        "## 3. Data loader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.cuda.empty_cache()  # Frees unused GPU memory\n",
        "# torch.cuda.memory_summary(device=None, abbreviated=False)  # Prints memory usage"
      ],
      "metadata": {
        "id": "cysZ3QGQYejM"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "id": "55QzoBXZ4eFQ"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# initialize the dataloader\n",
        "batch_size = 8 # due to cuda out of memory issue\n",
        "train_dataloader = DataLoader(\n",
        "    tokenized_datasets['train'],\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True\n",
        ")\n",
        "eval_dataloader = DataLoader(\n",
        "    tokenized_datasets['validation'],\n",
        "    batch_size=batch_size\n",
        ")\n",
        "test_dataloader = DataLoader(\n",
        "    tokenized_datasets['test'],\n",
        "    batch_size=batch_size\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U8W5yw6n4eFQ",
        "outputId": "c83a3d61-a985-474a-aac1-e8c71a3bb915"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 1000])\n",
            "torch.Size([8, 1000])\n",
            "torch.Size([8, 1000])\n",
            "torch.Size([8, 1000])\n",
            "torch.Size([8])\n"
          ]
        }
      ],
      "source": [
        "for batch in train_dataloader:\n",
        "    print(batch['premise_input_ids'].shape)\n",
        "    print(batch['premise_attention_mask'].shape)\n",
        "    print(batch['hypothesis_input_ids'].shape)\n",
        "    print(batch['hypothesis_attention_mask'].shape)\n",
        "    print(batch['labels'].shape)\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2hsXI0z4eFR"
      },
      "source": [
        "## 4. Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "id": "H7l-zYDo4eFR"
      },
      "outputs": [],
      "source": [
        "# start from a pretrained bert-base-uncased model\n",
        "# from transformers import BertTokenizer, BertModel\n",
        "# model = BertModel.from_pretrained('bert-base-uncased')\n",
        "# model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# embedding\n",
        "class Embedding(nn.Module):\n",
        "    def __init__(self, vocab_size, max_len, n_segments, d_model, device):\n",
        "        super(Embedding, self).__init__()\n",
        "        self.tok_embed = nn.Embedding(vocab_size, d_model)  # token embedding\n",
        "        self.pos_embed = nn.Embedding(max_len, d_model)      # position embedding\n",
        "        self.seg_embed = nn.Embedding(n_segments, d_model)  # segment(token type) embedding\n",
        "        self.norm = nn.LayerNorm(d_model)\n",
        "        self.device = device\n",
        "\n",
        "    def forward(self, x, seg):\n",
        "        #x, seg: (bs, len)\n",
        "        seq_len = x.size(1)\n",
        "        pos = torch.arange(seq_len, dtype=torch.long).to(self.device)\n",
        "        pos = pos.unsqueeze(0).expand_as(x)  # (len,) -> (bs, len)\n",
        "        embedding = self.tok_embed(x) + self.pos_embed(pos) + self.seg_embed(seg)\n",
        "        return self.norm(embedding)"
      ],
      "metadata": {
        "id": "_tyAIFLJK0y7"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# scaled dot attention\n",
        "class ScaledDotProductAttention(nn.Module):\n",
        "    def __init__(self, d_k, device):\n",
        "        super(ScaledDotProductAttention, self).__init__()\n",
        "        self.scale = torch.sqrt(torch.FloatTensor([d_k])).to(device)\n",
        "\n",
        "    def forward(self, Q, K, V, attn_mask):\n",
        "        scores = torch.matmul(Q, K.transpose(-1, -2)) / self.scale # scores : [batch_size x n_heads x len_q(=len_k) x len_k(=len_q)]\n",
        "        scores.masked_fill_(attn_mask, -1e9) # Fills elements of self tensor with value where mask is one.\n",
        "        attn = nn.Softmax(dim=-1)(scores)\n",
        "        context = torch.matmul(attn, V)\n",
        "        return context, attn"
      ],
      "metadata": {
        "id": "FqJSlKHVLdVp"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# multihead attention\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, n_heads, d_model, d_k, device):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.n_heads = n_heads\n",
        "        self.d_model = d_model\n",
        "        self.d_k = d_k\n",
        "        self.d_v = d_k\n",
        "        self.W_Q = nn.Linear(d_model, d_k * n_heads)\n",
        "        self.W_K = nn.Linear(d_model, d_k * n_heads)\n",
        "        self.W_V = nn.Linear(d_model, self.d_v * n_heads)\n",
        "        self.device = device\n",
        "    def forward(self, Q, K, V, attn_mask):\n",
        "        # q: [batch_size x len_q x d_model], k: [batch_size x len_k x d_model], v: [batch_size x len_k x d_model]\n",
        "        residual, batch_size = Q, Q.size(0)\n",
        "        # (B, S, D) -proj-> (B, S, D) -split-> (B, S, H, W) -trans-> (B, H, S, W)\n",
        "        q_s = self.W_Q(Q).view(batch_size, -1, self.n_heads, self.d_k).transpose(1,2)  # q_s: [batch_size x n_heads x len_q x d_k]\n",
        "        k_s = self.W_K(K).view(batch_size, -1, self.n_heads, self.d_k).transpose(1,2)  # k_s: [batch_size x n_heads x len_k x d_k]\n",
        "        v_s = self.W_V(V).view(batch_size, -1, self.n_heads, self.d_v).transpose(1,2)  # v_s: [batch_size x n_heads x len_k x d_v]\n",
        "\n",
        "        attn_mask = attn_mask.unsqueeze(1).repeat(1, self.n_heads, 1, 1) # attn_mask : [batch_size x n_heads x len_q x len_k]\n",
        "\n",
        "        # context: [batch_size x n_heads x len_q x d_v], attn: [batch_size x n_heads x len_q(=len_k) x len_k(=len_q)]\n",
        "        context, attn = ScaledDotProductAttention(self.d_k, self.device)(q_s, k_s, v_s, attn_mask)\n",
        "        context = context.transpose(1, 2).contiguous().view(batch_size, -1, self.n_heads * self.d_v) # context: [batch_size x len_q x n_heads * d_v]\n",
        "        output = nn.Linear(self.n_heads * self.d_v, self.d_model, device=self.device)(context)\n",
        "        return nn.LayerNorm(self.d_model, device=self.device)(output + residual), attn # output: [batch_size x len_q x d_model]"
      ],
      "metadata": {
        "id": "qL1YCdBHLXMT"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# poswisefeedforwardnet\n",
        "class PoswiseFeedForwardNet(nn.Module):\n",
        "    def __init__(self, d_model, d_ff):\n",
        "        super(PoswiseFeedForwardNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(d_model, d_ff)\n",
        "        self.fc2 = nn.Linear(d_ff, d_model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # (batch_size, len_seq, d_model) -> (batch_size, len_seq, d_ff) -> (batch_size, len_seq, d_model)\n",
        "        return self.fc2(F.gelu(self.fc1(x)))"
      ],
      "metadata": {
        "id": "iXUf8f20Lj9p"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# encoder\n",
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, n_heads, d_model, d_ff, d_k, device):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "        self.enc_self_attn = MultiHeadAttention(n_heads, d_model, d_k, device)\n",
        "        self.pos_ffn       = PoswiseFeedForwardNet(d_model, d_ff)\n",
        "\n",
        "    def forward(self, enc_inputs, enc_self_attn_mask):\n",
        "        enc_outputs, attn = self.enc_self_attn(enc_inputs, enc_inputs, enc_inputs, enc_self_attn_mask) # enc_inputs to same Q,K,V\n",
        "        enc_outputs = self.pos_ffn(enc_outputs) # enc_outputs: [batch_size x len_q x d_model]\n",
        "        return enc_outputs, attn"
      ],
      "metadata": {
        "id": "7ZNMsPaeK5Sx"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# attention mask\n",
        "def get_attn_pad_mask(seq_q, seq_k, device):\n",
        "    batch_size, len_q = seq_q.size()\n",
        "    batch_size, len_k = seq_k.size()\n",
        "    # eq(zero) is PAD token\n",
        "    pad_attn_mask = seq_k.data.eq(0).unsqueeze(1).to(device)  # batch_size x 1 x len_k(=len_q), one is masking\n",
        "    return pad_attn_mask.expand(batch_size, len_q, len_k)  # batch_size x len_q x len_k"
      ],
      "metadata": {
        "id": "PJT_oxqgKry8"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BERT(nn.Module):\n",
        "    def __init__(self, n_layers, n_heads, d_model, d_ff, d_k, n_segments, vocab_size, max_len, device):\n",
        "        super(BERT, self).__init__()\n",
        "        self.params = {'n_layers': n_layers, 'n_heads': n_heads, 'd_model': d_model,\n",
        "                       'd_ff': d_ff, 'd_k': d_k, 'n_segments': n_segments,\n",
        "                       'vocab_size': vocab_size, 'max_len': max_len}\n",
        "        self.embedding = Embedding(vocab_size, max_len, n_segments, d_model, device)\n",
        "        self.layers = nn.ModuleList([EncoderLayer(n_heads, d_model, d_ff, d_k, device) for _ in range(n_layers)])\n",
        "        self.fc = nn.Linear(d_model, d_model)\n",
        "        self.activ = nn.Tanh()\n",
        "        self.linear = nn.Linear(d_model, d_model)\n",
        "        self.norm = nn.LayerNorm(d_model)\n",
        "        self.classifier = nn.Linear(d_model, 2)\n",
        "        # decoder is shared with embedding layer\n",
        "        embed_weight = self.embedding.tok_embed.weight\n",
        "        n_vocab, n_dim = embed_weight.size()\n",
        "        self.decoder = nn.Linear(n_dim, n_vocab, bias=False)\n",
        "        self.decoder.weight = embed_weight\n",
        "        self.decoder_bias = nn.Parameter(torch.zeros(n_vocab))\n",
        "        self.device = device\n",
        "\n",
        "    def forward(self, input_ids, segment_ids, masked_pos):\n",
        "        output = self.embedding(input_ids, segment_ids)\n",
        "        enc_self_attn_mask = get_attn_pad_mask(input_ids, input_ids, self.device)\n",
        "        for layer in self.layers:\n",
        "            output, enc_self_attn = layer(output, enc_self_attn_mask)\n",
        "        # output : [batch_size, len, d_model], attn : [batch_size, n_heads, d_mode, d_model]\n",
        "\n",
        "        # 1. predict next sentence\n",
        "        # it will be decided by first token(CLS)\n",
        "        h_pooled   = self.activ(self.fc(output[:, 0])) # [batch_size, d_model]\n",
        "        logits_nsp = self.classifier(h_pooled) # [batch_size, 2]\n",
        "\n",
        "        # 2. predict the masked token\n",
        "        masked_pos = masked_pos[:, :, None].expand(-1, -1, output.size(-1)) # [batch_size, max_pred, d_model]\n",
        "        h_masked = torch.gather(output, 1, masked_pos) # masking position [batch_size, max_pred, d_model]\n",
        "        h_masked  = self.norm(F.gelu(self.linear(h_masked)))\n",
        "        logits_lm = self.decoder(h_masked) + self.decoder_bias # [batch_size, max_pred, n_vocab]\n",
        "\n",
        "        return logits_lm, logits_nsp\n",
        "\n",
        "    def get_last_hidden_state(self, input_ids, segment_ids):\n",
        "        output = self.embedding(input_ids, segment_ids)\n",
        "        enc_self_attn_mask = get_attn_pad_mask(input_ids, input_ids, self.device)\n",
        "        for layer in self.layers:\n",
        "            output, enc_self_attn = layer(output, enc_self_attn_mask)\n",
        "\n",
        "        return output"
      ],
      "metadata": {
        "id": "JUNHnRU3Kl-F"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = BERT(\n",
        "    n_layers,\n",
        "    n_heads,\n",
        "    d_model,\n",
        "    d_ff,\n",
        "    d_k,\n",
        "    n_segments,\n",
        "    vocab_size,\n",
        "    max_len,\n",
        "    device\n",
        ")\n",
        "model.load_state_dict(torch.load('models/bert_model.pt'))\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "bJ5eZMYzKY3j",
        "outputId": "746cd092-b6f9-4ef0-b3ec-e29dd46ccbd0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-134-93cff7838cbc>:12: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load('models/bert_model.pt'))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BERT(\n",
              "  (embedding): Embedding(\n",
              "    (tok_embed): Embedding(23068, 768)\n",
              "    (pos_embed): Embedding(1000, 768)\n",
              "    (seg_embed): Embedding(2, 768)\n",
              "    (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (layers): ModuleList(\n",
              "    (0-5): 6 x EncoderLayer(\n",
              "      (enc_self_attn): MultiHeadAttention(\n",
              "        (W_Q): Linear(in_features=768, out_features=512, bias=True)\n",
              "        (W_K): Linear(in_features=768, out_features=512, bias=True)\n",
              "        (W_V): Linear(in_features=768, out_features=512, bias=True)\n",
              "      )\n",
              "      (pos_ffn): PoswiseFeedForwardNet(\n",
              "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (fc): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (activ): Tanh()\n",
              "  (linear): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              "  (decoder): Linear(in_features=768, out_features=23068, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jo2L4Sao4eFS"
      },
      "source": [
        "### Pooling\n",
        "SBERT adds a pooling operation to the output of BERT / RoBERTa to derive a fixed sized sentence embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "id": "fPn7Onda4eFS"
      },
      "outputs": [],
      "source": [
        "# define mean pooling function\n",
        "def mean_pool(token_embeds, attention_mask):\n",
        "    # reshape attention_mask to cover 768-dimension embeddings\n",
        "    in_mask = attention_mask.unsqueeze(-1).expand(\n",
        "        token_embeds.size()\n",
        "    ).float()\n",
        "    # perform mean-pooling but exclude padding tokens (specified by in_mask)\n",
        "    pool = torch.sum(token_embeds * in_mask, 1) / torch.clamp(\n",
        "        in_mask.sum(1), min=1e-9\n",
        "    )\n",
        "    return pool"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YrQICCaE4eFS"
      },
      "source": [
        "## 5. Loss Function\n",
        "\n",
        "## Classification Objective Function\n",
        "We concatenate the sentence embeddings $u$ and $v$ with the element-wise difference  $\\lvert u - v \\rvert $ and multiply the result with the trainable weight  $ W_t ∈  \\mathbb{R}^{3n \\times k}  $:\n",
        "\n",
        "$ o = \\text{softmax}\\left(W^T \\cdot \\left(u, v, \\lvert u - v \\rvert\\right)\\right) $\n",
        "\n",
        "where $n$ is the dimension of the sentence embeddings and k the number of labels. We optimize cross-entropy loss. This structure is depicted in Figure 1.\n",
        "\n",
        "## Regression Objective Function.\n",
        "The cosine similarity between the two sentence embeddings $u$ and $v$ is computed (Figure 2). We use means quared-error loss as the objective function.\n",
        "\n",
        "(Manhatten / Euclidean distance, semantically  similar sentences can be found.)\n",
        "\n",
        "<img src=\"https://github.com/MyaMjechal/nlp-a4-do-you-agree-web-with-bert/blob/main/figures/sbert-architecture.png?raw=1\" >"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "id": "7Y_ZyS1n4eFT"
      },
      "outputs": [],
      "source": [
        "def configurations(u,v):\n",
        "    # build the |u-v| tensor\n",
        "    uv = torch.sub(u, v)   # batch_size,hidden_dim\n",
        "    uv_abs = torch.abs(uv) # batch_size,hidden_dim\n",
        "\n",
        "    # concatenate u, v, |u-v|\n",
        "    x = torch.cat([u, v, uv_abs], dim=-1) # batch_size, 3*hidden_dim\n",
        "    return x\n",
        "\n",
        "def cosine_similarity(u, v):\n",
        "    dot_product = np.dot(u, v)\n",
        "    norm_u = np.linalg.norm(u)\n",
        "    norm_v = np.linalg.norm(v)\n",
        "    similarity = dot_product / (norm_u * norm_v)\n",
        "    return similarity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lH4R-69r4eFT"
      },
      "source": [
        "<img src=\"https://github.com/MyaMjechal/nlp-a4-do-you-agree-web-with-bert/blob/main/figures/sbert-ablation.png?raw=1\" width=\"350\" height=\"300\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "id": "GPVamTuq4eFT"
      },
      "outputs": [],
      "source": [
        "classifier_head = torch.nn.Linear(768*3, 3).to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=2e-5)\n",
        "optimizer_classifier = torch.optim.Adam(classifier_head.parameters(), lr=2e-5)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "id": "WrCLWRBr4eFT"
      },
      "outputs": [],
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# and setup a warmup for the first ~10% steps\n",
        "total_steps = int(len(raw_dataset) / batch_size)\n",
        "warmup_steps = int(0.1 * total_steps)\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "\t\toptimizer, num_warmup_steps=warmup_steps,\n",
        "  \tnum_training_steps=total_steps - warmup_steps\n",
        ")\n",
        "\n",
        "# then during the training loop we update the scheduler per step\n",
        "scheduler.step()\n",
        "\n",
        "scheduler_classifier = get_linear_schedule_with_warmup(\n",
        "\t\toptimizer_classifier, num_warmup_steps=warmup_steps,\n",
        "  \tnum_training_steps=total_steps - warmup_steps\n",
        ")\n",
        "\n",
        "# then during the training loop we update the scheduler per step\n",
        "scheduler_classifier.step()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_H1NR_b4eFU"
      },
      "source": [
        "## 6. Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381,
          "referenced_widgets": [
            "32134839181d4b0bb44c962a81d1fb41",
            "5aa6501ae4294020b1ca4a905710e3f6",
            "8d127d1eae2d40399a3d39840ce46d6f",
            "f89894d2d3ec494280aef145f6814b51",
            "676f028e94f74e3a882a250dab41ba7f",
            "60cfc2118d4d400ca0003166e1a01b83",
            "c7a8b3fefe5142d9a3d61339b6f3afa1",
            "1e6b2f3369084273ba835b01a47fc660",
            "550e61be4b3c4aef8bdc1af1c03a6aa0",
            "edee59d84fcc407a8ed431fa8d5bc0de",
            "cff07d06da174bd59cf8418e8c7f1119"
          ]
        },
        "id": "IPOmHFtc4eFU",
        "outputId": "90d98d76-e227-4a8f-c02a-cb004e4f2f4f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/125 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "32134839181d4b0bb44c962a81d1fb41"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "The expanded size of the tensor (5) must match the existing size (1000) at non-singleton dimension 1.  Target sizes: [8, 5, 23068].  Tensor sizes: [8, 1000, 1]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-139-37ddda85d3b2>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m          \u001b[0;31m# get the mean pooled vectors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mu_mean_pool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu_last_hidden_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_a\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# batch_size, hidden_dim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0mv_mean_pool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv_last_hidden_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_b\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# batch_size, hidden_dim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-135-8606a3734272>\u001b[0m in \u001b[0;36mmean_pool\u001b[0;34m(token_embeds, attention_mask)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmean_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_embeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# reshape attention_mask to cover 768-dimension embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     in_mask = attention_mask.unsqueeze(-1).expand(\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mtoken_embeds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     ).float()\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The expanded size of the tensor (5) must match the existing size (1000) at non-singleton dimension 1.  Target sizes: [8, 5, 23068].  Tensor sizes: [8, 1000, 1]"
          ]
        }
      ],
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "num_epoch = 5\n",
        "# 1 epoch should be enough, increase if wanted\n",
        "for epoch in range(num_epoch):\n",
        "    model.train()\n",
        "    classifier_head.train()\n",
        "    # initialize the dataloader loop with tqdm (tqdm == progress bar)\n",
        "    for step, batch in enumerate(tqdm(train_dataloader, leave=True)):\n",
        "        # zero all gradients on each new step\n",
        "        optimizer.zero_grad()\n",
        "        optimizer_classifier.zero_grad()\n",
        "\n",
        "        # prepare batches and more all to the active device\n",
        "        inputs_ids_a = batch['premise_input_ids'].to(device)\n",
        "        inputs_ids_b = batch['hypothesis_input_ids'].to(device)\n",
        "        attention_a = batch['premise_attention_mask'].to(device)\n",
        "        attention_b = batch['hypothesis_attention_mask'].to(device)\n",
        "        label = batch['labels'].to(device)\n",
        "\n",
        "        segment_ids = torch.tensor([0] * max_len).unsqueeze(0).repeat(inputs_ids_a.shape[0], 1).to(device)\n",
        "        masked_pos = torch.tensor([0] * max_mask).unsqueeze(0).repeat(inputs_ids_a.shape[0], 1).to(device)\n",
        "\n",
        "        # segment_ids = torch.tensor([0] * max_len).unsqueeze(0).repeat(batch_size, 1).to(device)\n",
        "        # masked_pos = torch.tensor([0] * max_mask).unsqueeze(0).repeat(batch_size, 1).to(device)\n",
        "\n",
        "        # extract token embeddings from BERT at last_hidden_state\n",
        "        u, _ = model(inputs_ids_a, segment_ids, masked_pos)\n",
        "        v, _ = model(inputs_ids_b, segment_ids, masked_pos)\n",
        "\n",
        "        u_last_hidden_state = u # all token embeddings A = batch_size, seq_len, hidden_dim\n",
        "        v_last_hidden_state = v # all token embeddings B = batch_size, seq_len, hidden_dim\n",
        "\n",
        "         # get the mean pooled vectors\n",
        "        u_mean_pool = mean_pool(u_last_hidden_state, attention_a) # batch_size, hidden_dim\n",
        "        v_mean_pool = mean_pool(v_last_hidden_state, attention_b) # batch_size, hidden_dim\n",
        "\n",
        "        # build the |u-v| tensor\n",
        "        uv = torch.sub(u_mean_pool, v_mean_pool)   # batch_size,hidden_dim\n",
        "        uv_abs = torch.abs(uv) # batch_size,hidden_dim\n",
        "\n",
        "        # concatenate u, v, |u-v|\n",
        "        x = torch.cat([u_mean_pool, v_mean_pool, uv_abs], dim=-1) # batch_size, 3*hidden_dim\n",
        "\n",
        "        # process concatenated tensor through classifier_head\n",
        "        x = classifier_head(x) #batch_size, classifer\n",
        "\n",
        "        # calculate the 'softmax-loss' between predicted and true label\n",
        "        loss = criterion(x, label)\n",
        "\n",
        "        # using loss, calculate gradients and then optimizerize\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer_classifier.step()\n",
        "\n",
        "        scheduler.step() # update learning rate scheduler\n",
        "        scheduler_classifier.step()\n",
        "\n",
        "    print(f'Epoch: {epoch + 1} | loss = {loss.item():.6f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lBTuZsPk4eFU"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "classifier_head.eval()\n",
        "total_similarity = 0\n",
        "with torch.no_grad():\n",
        "    for step, batch in enumerate(eval_dataloader):\n",
        "        # prepare batches and more all to the active device\n",
        "        inputs_ids_a = batch['premise_input_ids'].to(device)\n",
        "        inputs_ids_b = batch['hypothesis_input_ids'].to(device)\n",
        "        attention_a = batch['premise_attention_mask'].to(device)\n",
        "        attention_b = batch['hypothesis_attention_mask'].to(device)\n",
        "        label = batch['labels'].to(device)\n",
        "\n",
        "        # extract token embeddings from BERT at last_hidden_state\n",
        "        u = model(inputs_ids_a, attention_mask=attention_a)[0]  # all token embeddings A = batch_size, seq_len, hidden_dim\n",
        "        v = model(inputs_ids_b, attention_mask=attention_b)[0]  # all token embeddings B = batch_size, seq_len, hidden_dim\n",
        "\n",
        "        # get the mean pooled vectors\n",
        "        u_mean_pool = mean_pool(u, attention_a).detach().cpu().numpy().reshape(-1) # batch_size, hidden_dim\n",
        "        v_mean_pool = mean_pool(v, attention_b).detach().cpu().numpy().reshape(-1) # batch_size, hidden_dim\n",
        "\n",
        "        similarity_score = cosine_similarity(u_mean_pool, v_mean_pool)\n",
        "        total_similarity += similarity_score\n",
        "\n",
        "average_similarity = total_similarity / len(eval_dataloader)\n",
        "print(f\"Average Cosine Similarity: {average_similarity:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hwvAmq54eFV"
      },
      "source": [
        "## 7. Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5sk570Gu4eFV"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def calculate_similarity(model, tokenizer, sentence_a, sentence_b, device):\n",
        "    # Tokenize and convert sentences to input IDs and attention masks\n",
        "    inputs_a = tokenizer(sentence_a, return_tensors='pt', truncation=True, padding=True).to(device)\n",
        "    inputs_b = tokenizer(sentence_b, return_tensors='pt', truncation=True, padding=True).to(device)\n",
        "\n",
        "    # Move input IDs and attention masks to the active device\n",
        "    inputs_ids_a = inputs_a['input_ids']\n",
        "    attention_a = inputs_a['attention_mask']\n",
        "    inputs_ids_b = inputs_b['input_ids']\n",
        "    attention_b = inputs_b['attention_mask']\n",
        "\n",
        "    # Extract token embeddings from BERT\n",
        "    u = model(inputs_ids_a, attention_mask=attention_a)[0]  # all token embeddings A = batch_size, seq_len, hidden_dim\n",
        "    v = model(inputs_ids_b, attention_mask=attention_b)[0]  # all token embeddings B = batch_size, seq_len, hidden_dim\n",
        "\n",
        "    # Get the mean-pooled vectors\n",
        "    u = mean_pool(u, attention_a).detach().cpu().numpy().reshape(-1)  # batch_size, hidden_dim\n",
        "    v = mean_pool(v, attention_b).detach().cpu().numpy().reshape(-1)  # batch_size, hidden_dim\n",
        "\n",
        "    # Calculate cosine similarity\n",
        "    similarity_score = cosine_similarity(u.reshape(1, -1), v.reshape(1, -1))[0, 0]\n",
        "\n",
        "    return similarity_score\n",
        "\n",
        "# Example usage:\n",
        "sentence_a = 'Your contribution helped make it possible for us to provide our students with a quality education.'\n",
        "sentence_b = \"Your contributions were of no help with our students' education.\"\n",
        "similarity = calculate_similarity(model, tokenizer, sentence_a, sentence_b, device)\n",
        "print(f\"Cosine Similarity: {similarity:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jbNrLuw_4eFW"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Move model and classifier head to evaluation mode\n",
        "model.eval()\n",
        "classifier_head.eval()\n",
        "\n",
        "# Function to get predictions using classifier head\n",
        "def predict(model, classifier_head, dataset, device):\n",
        "    predictions = []\n",
        "\n",
        "    for example in dataset:\n",
        "        # Tokenize input sentences\n",
        "        inputs_a = tokenizer(example[\"premise\"], return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
        "        inputs_b = tokenizer(example[\"hypothesis\"], return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
        "\n",
        "        # Extract embeddings from BERT\n",
        "        with torch.no_grad():\n",
        "            u = model(inputs_a[\"input_ids\"], attention_mask=inputs_a[\"attention_mask\"])\n",
        "            v = model(inputs_b[\"input_ids\"], attention_mask=inputs_b[\"attention_mask\"])\n",
        "\n",
        "        # Extract last hidden states\n",
        "        u_last_hidden_state = u.last_hidden_state  # Shape: (batch_size, seq_len, hidden_dim)\n",
        "        v_last_hidden_state = v.last_hidden_state  # Shape: (batch_size, seq_len, hidden_dim)\n",
        "\n",
        "        # Perform mean pooling to get fixed-size sentence embeddings\n",
        "        u_mean_pool = mean_pool(u_last_hidden_state, inputs_a[\"attention_mask\"])\n",
        "        v_mean_pool = mean_pool(v_last_hidden_state, inputs_b[\"attention_mask\"])\n",
        "\n",
        "        # Concatenate u, v, and |u - v| (As used in training)\n",
        "        x = torch.cat([u_mean_pool, v_mean_pool, torch.abs(u_mean_pool - v_mean_pool)], dim=-1)\n",
        "\n",
        "        # Pass through classifier head to get logits\n",
        "        logits = classifier_head(x)\n",
        "\n",
        "        # Get predicted label\n",
        "        predicted_label = torch.argmax(logits, dim=1).item()\n",
        "        predictions.append(predicted_label)\n",
        "\n",
        "    return predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Matthews Correlation Coefficient & F1-Score for Classification"
      ],
      "metadata": {
        "id": "0FQScltrDT0Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report, matthews_corrcoef, f1_score\n",
        "\n",
        "# Get predictions on validation set\n",
        "predictions = predict(model, classifier_head, raw_dataset['validation'], device)\n",
        "\n",
        "# Extract true labels\n",
        "true_labels = np.array([ex['label'] for ex in raw_dataset['validation']])\n",
        "\n",
        "# Compute Accuracy\n",
        "accuracy = accuracy_score(true_labels, predictions)\n",
        "\n",
        "# Compute MCC\n",
        "mcc = matthews_corrcoef(true_labels, predictions)\n",
        "\n",
        "# Compute F1-score (macro handles class imbalance better)\n",
        "f1 = f1_score(true_labels, predictions, average='macro')\n",
        "\n",
        "# Print all metrics\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Matthews Correlation Coefficient (MCC): {mcc:.4f}\")\n",
        "print(f\"F1 Score (Macro): {f1:.4f}\")\n",
        "print(\"\\nClassification Report:\\n\", classification_report(true_labels, predictions, target_names=[\"entailment\", \"neutral\", \"contradiction\"]))"
      ],
      "metadata": {
        "id": "C57AORkBDBR4"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7e81c0c326e04a18803754d5e904e5fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ebcae985a50346f69f7ddb692afe8189",
              "IPY_MODEL_c624ed196d7441bc9a410c405f7acc7f",
              "IPY_MODEL_d5d0729cf41f4d31b477dff131126b9e"
            ],
            "layout": "IPY_MODEL_77405024f8064cd4a170025915c8471b"
          }
        },
        "ebcae985a50346f69f7ddb692afe8189": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_75d9594f9de24dbdb0a418bf80c8aad2",
            "placeholder": "​",
            "style": "IPY_MODEL_768216801daa4cfd83501973a88ceb02",
            "value": "Map: 100%"
          }
        },
        "c624ed196d7441bc9a410c405f7acc7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_688dd0efc83246af86c090ecf240f4c0",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d39473546d884aff859874ff5f490912",
            "value": 1000
          }
        },
        "d5d0729cf41f4d31b477dff131126b9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e922d291ba2f42be96083ef95c6c73ad",
            "placeholder": "​",
            "style": "IPY_MODEL_ac12b1cc0ab747d59ed84e8a96c598cd",
            "value": " 1000/1000 [00:00&lt;00:00, 1104.18 examples/s]"
          }
        },
        "77405024f8064cd4a170025915c8471b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75d9594f9de24dbdb0a418bf80c8aad2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "768216801daa4cfd83501973a88ceb02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "688dd0efc83246af86c090ecf240f4c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d39473546d884aff859874ff5f490912": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e922d291ba2f42be96083ef95c6c73ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac12b1cc0ab747d59ed84e8a96c598cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5a3b3c296f184bd99d4e7250804c793a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4a9c26e8416b4d85b9c59665fe2b4a8d",
              "IPY_MODEL_067e14930efb4276a6760e062851b097",
              "IPY_MODEL_4e1e0d8e6ae443ee9237ad0f5cc9e160"
            ],
            "layout": "IPY_MODEL_8dc9dd0af210478292f55d5313215c5a"
          }
        },
        "4a9c26e8416b4d85b9c59665fe2b4a8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6caa264a4b842fc91e91f60c7e62db6",
            "placeholder": "​",
            "style": "IPY_MODEL_b2b960b3d485497d9bcc3fbc3516e204",
            "value": "Map: 100%"
          }
        },
        "067e14930efb4276a6760e062851b097": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_028633e30f494158a0434d9967575635",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c7ae49b0f716435087acb1100fefe424",
            "value": 1000
          }
        },
        "4e1e0d8e6ae443ee9237ad0f5cc9e160": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_78fa846e08054c8abad5ba11eee47c3b",
            "placeholder": "​",
            "style": "IPY_MODEL_9bedd0fcab51468780fae38a7b8e5225",
            "value": " 1000/1000 [00:00&lt;00:00, 1189.33 examples/s]"
          }
        },
        "8dc9dd0af210478292f55d5313215c5a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6caa264a4b842fc91e91f60c7e62db6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2b960b3d485497d9bcc3fbc3516e204": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "028633e30f494158a0434d9967575635": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7ae49b0f716435087acb1100fefe424": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "78fa846e08054c8abad5ba11eee47c3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9bedd0fcab51468780fae38a7b8e5225": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5c36d2e081054584a8fd7ec498847191": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9c8649c87f8d44e39b08f423d31aebb3",
              "IPY_MODEL_0eddb1d78814464e85040352e02b3944",
              "IPY_MODEL_d33e2358fe0a4d6a9ca06b5d3e89e8b1"
            ],
            "layout": "IPY_MODEL_f9d3fd2a50d2443f83862752de47f421"
          }
        },
        "9c8649c87f8d44e39b08f423d31aebb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ccff32da445c4ea78ded721be7ba6b90",
            "placeholder": "​",
            "style": "IPY_MODEL_dbdcc8c18e1549aaba47941c37b81b86",
            "value": "Map: 100%"
          }
        },
        "0eddb1d78814464e85040352e02b3944": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c0ce57ad8d345a5b090aeec1484ebca",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_76c85b7735774ae3bc0a9a880498155f",
            "value": 1000
          }
        },
        "d33e2358fe0a4d6a9ca06b5d3e89e8b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b1376d55c474745bb8812c67a992d50",
            "placeholder": "​",
            "style": "IPY_MODEL_608ac528701d4cb9947a32447a4fd7e6",
            "value": " 1000/1000 [00:00&lt;00:00, 1156.23 examples/s]"
          }
        },
        "f9d3fd2a50d2443f83862752de47f421": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ccff32da445c4ea78ded721be7ba6b90": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbdcc8c18e1549aaba47941c37b81b86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5c0ce57ad8d345a5b090aeec1484ebca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76c85b7735774ae3bc0a9a880498155f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5b1376d55c474745bb8812c67a992d50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "608ac528701d4cb9947a32447a4fd7e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "32134839181d4b0bb44c962a81d1fb41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5aa6501ae4294020b1ca4a905710e3f6",
              "IPY_MODEL_8d127d1eae2d40399a3d39840ce46d6f",
              "IPY_MODEL_f89894d2d3ec494280aef145f6814b51"
            ],
            "layout": "IPY_MODEL_676f028e94f74e3a882a250dab41ba7f"
          }
        },
        "5aa6501ae4294020b1ca4a905710e3f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60cfc2118d4d400ca0003166e1a01b83",
            "placeholder": "​",
            "style": "IPY_MODEL_c7a8b3fefe5142d9a3d61339b6f3afa1",
            "value": "  0%"
          }
        },
        "8d127d1eae2d40399a3d39840ce46d6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e6b2f3369084273ba835b01a47fc660",
            "max": 125,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_550e61be4b3c4aef8bdc1af1c03a6aa0",
            "value": 0
          }
        },
        "f89894d2d3ec494280aef145f6814b51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_edee59d84fcc407a8ed431fa8d5bc0de",
            "placeholder": "​",
            "style": "IPY_MODEL_cff07d06da174bd59cf8418e8c7f1119",
            "value": " 0/125 [00:07&lt;?, ?it/s]"
          }
        },
        "676f028e94f74e3a882a250dab41ba7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60cfc2118d4d400ca0003166e1a01b83": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7a8b3fefe5142d9a3d61339b6f3afa1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1e6b2f3369084273ba835b01a47fc660": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "550e61be4b3c4aef8bdc1af1c03a6aa0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "edee59d84fcc407a8ed431fa8d5bc0de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cff07d06da174bd59cf8418e8c7f1119": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}